---
tags:
  - university-notes
university-name: Virtual University of Pakistan
date: 2025-04-23
---

# 21. Null Spaces, Column Spaces, and Linear Transformations

<span style="color: gray;">Dated: 23-04-2025</span>

In applications of `linear algebra`, `subspaces` of $\mathbb R^n$ usually arise in one of the two ways

- As a `set`[^1] of all solutions to a system of `homogeneous linear equations`[^2]
- As a `set`[^1] of all `linear combinations` of certain specified `vectors`.[^3]

## Null Space

### Intuition

$$
\begin{aligned}
	x_1 - 3x_2 - 2x_3 = 0 \\
	-5x_1 + 9x_2 + x_3 = 0
\end{aligned}
$$

This can be written in $A \vec x = \vec 0$ form.

$$
A = \begin{bmatrix}
	1 & -3 & -2 \\
	-5 & 9 & 1
\end{bmatrix}
$$

Here $\vec x$ can be thought of solution `set`[^1] for this `homogeneous linear system`.[^2]  
$A$ being a `linear operator`, transforms $\vec x$ (the whole `set`[^1]) into $\vec 0$.  
Therefore, $\vec x$ is called the `null space`.

### Definition

The `null space` of $A_{m \times n}$ is the solution `set`[^1] of the `homogeneous linear equation`[^2] $A \vec x = \vec 0$.  

$$Nul(A) = \{x : x \in \mathbb R^n, A \vec x = \vec 0\}$$

### Example

$$
A = \begin{bmatrix}
	1 & -3 & -2 \\
	-5 & 9 & 1
\end{bmatrix}
$$

$$
\vec u = \begin{bmatrix}
	5 \\
	3 \\
	-2
\end{bmatrix}
$$

Determine if $\vec u \in Nul(A)$

#### Solution

$$\vec u \in Nul(A) \implies A \vec u = \vec 0$$

$$
Au = \begin{bmatrix}
1 & -3 & -2 \\
-5 & 9 & 1
\end{bmatrix}
\begin{bmatrix}
5 \\
3 \\
-2
\end{bmatrix}
=
\begin{bmatrix}
5 - 9 + 4 \\
-25 + 27 - 2
\end{bmatrix}
=
\begin{bmatrix}
0 \\
0
\end{bmatrix}
$$

Therefore, $\vec u$ _is_ in $Nul(A)$.

### Example

Determine the [null space](#null-space) of the following `matrix`[^4]

$$
A = \begin{bmatrix}
	4 & 0 \\
	-8 & 20
\end{bmatrix}
$$

#### Solution

$$
\begin{bmatrix}
4 & 0 \\
-8 & 20
\end{bmatrix}
\begin{bmatrix}
x_1 \\
x_2
\end{bmatrix}
=
\begin{bmatrix}
0 \\
0
\end{bmatrix} \\
\implies
\begin{bmatrix}
4x_1 + 0x_2 \\
-8x_1 + 20x_2
\end{bmatrix}
=
\begin{bmatrix}
0 \\
0
\end{bmatrix}
$$

$$
\begin{aligned}
	\implies 4x_1 + 0x_2 = 0 \implies x_1 = 0 \\
	\implies -8x_1 + 20x_2 = 0 \implies x_2 = 0
\end{aligned}
$$

Therefore, the [null space](#null-space) of $A$ is $\{\vec 0\}$.

### Theorem

`Elementary row operations`[^5] do not change the [null space](#null-space) of a `matrix`.[^4]

### Theorem

The [null space](#null-space) of $A_{m \times n}$ is a `subspace` of $\mathbb R^n$.

### Example

Find `spanning set` for the [null space](#null-space) of the `matrix`.[^4]

$$
A = \begin{bmatrix}
	-3 & 6 & -1 & 1 & -7 \\
	1 & -2 & 2 & 3 & -1 \\
	2 & -4 & 5 & 8 & -4
\end{bmatrix}
$$

#### Solution

After `row reducing`[^6] to `echelon form`[^6] of $[A \quad \vec 0]$, we have

$$
\begin{bmatrix}
	1 & -2 & 0 & -1 & 3 & 0 \\
	0 & 0 & 1 & 2 & -2 & 0 \\
	0 & 0 & 0 & 0 & 0 & 0
\end{bmatrix}
$$

$$
\begin{array}{cccccccccccccccc}
	x_1 &- &2&x_2 &&& &- &&x_4 &+ &3&x_5 &= &0 \\
	&&&&&&x_3 &+ &2&x_4 &- &2&x_5 &= &0 \\
	&&&&&&&&&&&0& &= &0
\end{array}
$$

The general solution is  

$$x_1 = 2x_2 + x_4 - 3x_5$$

$$x_2 = \text{free variable}$$

$$x_3 = -2x_4 + 2x_5$$

$$x_4 = \text{free variable}$$

$$x_5 = \text{free variable}$$

$$
\begin{array}{cccccccccccc}
	\begin{bmatrix}
		x_1 \\
		x_2 \\
		x_3 \\
		x_4 \\
		x_5 
	\end{bmatrix} &=
	&\begin{bmatrix}
		2x_2 + x_4 - 3x_5\\
		x_2\\
		-2x_4 + 2x_5\\
		x_4\\
		x_5
	\end{bmatrix} &=
	&x_2
	&\begin{bmatrix}
		2\\
		1\\
		0\\
		0\\
		0\\
	\end{bmatrix} &+
	&x_4
	&\begin{bmatrix}
		1\\
		0\\
		-2\\
		1\\
		0\\
	\end{bmatrix} &+
	&x_5
	&\begin{bmatrix}
		-3\\
		0\\
		2\\
		0\\
		1
	\end{bmatrix}\\
	&&&&&\Big\uparrow &&&\Big\uparrow &&&\Big\uparrow\\
	&&&&&\vec u &&& \vec v &&& \vec w
\end{array}
$$

$$= x_2 \vec u + x_4 \vec v + x_5 \vec w$$

Every `linear combination`[^2] of $\vec u, \vec v, \vec w$ is an element of $Nul(A)$.  
Thus $\{\vec u, \vec v, \vec w\}$ is a spanning `set`[^1] for $Nul(A)$.

- The spanning `set`[^1] is automatically `linearly independent`[^7] because the free `variables` are the weights of spanning `vectors`[^3]
- When $Nul(A)$ contains non zero `vector`,[^3] the number of `vectors`[^3] in the spanning `set`[^1] equals to the number of free `variables` in equation $A \vec x = \vec 0$.

## The Column Space of a Matrix

`Column space` is defined explicitly via `linear combinations`.[^8]

## Definition

If $A_{m \times n} = [a_1 \quad a_2 \quad \ldots \quad a_n]$ written as $Col \, A$ is the `set`[^1] of all `linear combinations`[^8] of the columns of $A$.  

$$Col \, (A) = Span\{a_1, a_2, \ldots, a_n\}$$

The `column space` of a `matrix`[^4] is that `subspace` spanned by the columns of the `matrix`[^4] (columns viewed as `vectors`[^3]).  
It is that space defined by all `linear combinations`[^8] of the column of the `matrix`.[^4]

## Theorem

The [column space](#column-space) of $A_{m \times n}$ is a `subspace` of $\mathbb R^m$.  

$$Col \, (A) = \{b : b = A \vec x \text{ for some } \vec x \in \mathbb R^n\}$$

## Example

Find a `matrix`[^4] $A$ such that $\mathbb W = Col \, (A)$

$$
\mathbb W = \left\{
\begin{bmatrix}
	6a - b\\
	a + b\\
	-7a
\end{bmatrix}
:
a, b \in \mathbb R
\right\}
$$

$$
W = \left\{ a \begin{bmatrix} 6 \\ 1 \\ -7 \end{bmatrix} + b \begin{bmatrix} -1 \\ 1 \\ 0 \end{bmatrix} : a, b \in \mathbb{R} \right\} = \text{Span} \left\{ \begin{bmatrix} 6 \\ 1 \\ -7 \end{bmatrix}, \begin{bmatrix} -1 \\ 1 \\ 0 \end{bmatrix} \right\}
$$

$$
A = \begin{bmatrix}
	6 & -1 \\
	1 & 1 \\
	-7 & 0
\end{bmatrix}
$$

## Theorem

A system of `linear equations`[^8] $A \vec x = \vec b$ is consistent if and only if $\vec b$ is in [column space](#column-space) of $A$.

## Theorem

If $x_0$ is a _particular_ solution to `linear combination`[^8] and $\vec {v_1}, \vec{v_2}, \ldots, \vec{v_k}$ form the solution `set`[^1] of the `homogeneous linear system`[^2] $A \vec x = \vec 0$ then _general_ solution can be written as $\vec x = \vec {x_0} + c_1 \vec {v_1} + c_2 \vec {v_2} + \ldots + c_n \vec {v_n}$.

## The Contrast between $Nul \, (A)$ and $Col \, (A)$

$$
A = \begin{bmatrix}
	2 & 4 & -2 & 1 \\
	-2 & -5 & 7 & 3 \\
	3 & 7 & -8 & 6
\end{bmatrix}
$$

- The columns of $A$ each have three `entries`,[^4] so Col $A$ is a `subspace` of $R^k$, where $k = 3$
- A `vector`[^3] $x$ such that $A \vec x$ is defined must have 4 `entries`,[^4] so $Nul \, (A)$ is a `subspace` of $R^k$, where $k = 4$.

When $A$ is `rectangular`, both $Nul (A)$ and $Col(A)$ exist in completely different universes.

| # | Nul $A$ | Col $A$ |
|---|---------|---------|
| 1 | Nul $A$ is a subspace of $\mathbb{R}^n$. | Col $A$ is a subspace of $\mathbb{R}^m$. |
| 2 | Nul $A$ is implicitly defined; i.e., we are given only a condition ($Ax = 0$) that vectors in Nul $A$ must satisfy. | Col $A$ is explicitly defined; that is, we are told how to build vectors in Col $A$. |
| 3 | It takes time to find vectors in Nul $A$. Row operations on $[A \ \ 0]$ are required. | It is easy to find vectors in Col $A$. The columns of $A$ are displayed; others are formed from them. |
| 4 | There is no obvious relation between Nul $A$ and the entries in $A$. | There is an obvious relation between Col $A$ and the entries in $A$, since each column of $A$ is in Col $A$. |
| 5 | A typical vector $v$ in Nul $A$ has the property that $Av = 0$. | A typical vector $v$ in Col $A$ has the property that the equation $Ax = v$ is consistent. |
| 6 | Given a specific vector $v$, it is easy to tell if $v$ is in Nul $A$. Just compute $Av$. | Given a specific vector $v$, it may take time to tell if $v$ is in Col $A$. Row operations on $[A \ \ v]$ are required. |
| 7 | Nul $A = \{0\}$ if and only if the equation $Ax = 0$ has only the trivial solution. | Col $A = \mathbb{R}^m$ if and only if the equation $Ax = b$ has a solution for every $b$ in $\mathbb{R}^m$. |
| 8 | Nul $A = \{0\}$ if and only if the linear transformation $x \mapsto Ax$ is one-to-one. | Col $A = \mathbb{R}^m$ if and only if the linear transformation $x \mapsto Ax$ maps $\mathbb{R}^n$ onto $\mathbb{R}^m$. |

## `Kernel`[^9] And `Range` of a `Linear Transformation`[^10]

`Subspaces` of `vector spaces` other than $R^n$ are often described in terms of a `linear transformation`[^10] instead of a `matrix`.[^4]

### Definition

A `linear transformation`[^10] $T$ from a `vector space` $\mathbb V$ into a `vector space` $\mathbb W$ is a rule that assigns to each `vector`[^3] $\vec x \in \mathbb V$ a unique `vector`[^3] $T(\vec x) \in \mathbb W$ such that

- $T(\vec u + \vec v) = T(\vec u) + T(\vec v) \quad \forall \vec u, \vec v \in \mathbb V$ 
- $T(c \vec u) = c T(\vec u) \quad \forall \vec u \in \mathbb V, c \in \mathbb R$

### Definition

If $T: \mathbb V \to \mathbb W$ is a `linear transformation`,[^10] then the `set`[^1] of `vectors`[^3] in $\mathbb V$ that $\mathbb T$ maps into $\vec 0$ is called the `kernel` of $T$.  
It is denoted by $ker(T)$.  
The `set`[^1] of all `vectors`[^3] in $\mathbb W$ that are images under $T$ of at least one `vector`[^3] in $\vec V$ is called the `range` of $T$.  
It is denoted by $R(T)$.

### Example

If $T_A : \mathbb R^n \to \mathbb R^m$ is multiplication by the $m \times n$ `matrix`[^4] $A$, then $kert(T_A)$ is the [null space](#null-space) of $A$ and the `range` of $T_A$ is the [column space](#column-space) of $A$.

### Remarks

The `kernel` of $T$ is a `subspace` of $\mathbb V$ and the `range` of $T$ is a `subspace` of $\mathbb W$.

## Example

Let $\mathbb V$ be the `vector space` of all real valued `functions`[^11] defined on the `interval`[^12] $[a, b]$ with property that they are `continuous`[^13] and `differentiable`.[^14]  
Let $\mathbb W$ be the `vector space` of all `continuous functions`[^13] on $[a, b]$ and let $D : \mathbb V \to \mathbb W$ be the `transformation`[^10] that changes $f$ in $\mathbb V$ into its `derivative`[^14] $f^\prime$.

$$D(f + g) = D(f) + D(g)$$

$$D(c f) = c D(f)$$

$Kert(D)$ is the `set`[^1] of the continuous `functions`[^11] of $[a, b]$ and the `range` of $D$ is the `set`[^1] $\mathbb W$ of all `continuous functions`[^13] on $[a, b]$.

## References

Read more about [[M_Notations|notations and symbols]].

[^1]: Read more about [[M_Set|sets]].
[^2]: Read more about [[mth501_07|homogeneous linear equations]].
[^3]: Read more about [[10. Introduction to vectors|vectors]].
[^4]: Read more about [[mth501_02|matrices]].
[^5]: Read more about [[mth501_04|row operations]].
[^6]: Read more about [[mth501_04|echelon form]].
[^7]: Read more about [[mth501_08|linear independence]].
[^8]: Read more about [[mth501_03|linear combinations and systems]].
[^9]: Read more about [[mth501_10|kernel]].
[^10]: Read more about [[mth501_09|linear transformations]].
[^11]: Read more about [[M_Function|functions]].
[^12]: Read more about [[1. Coordinates, Graphs, Lines|intervals]].
[^13]: Read more about [[12. Continuity|continuity]].
[^14]: Read more about [[15. The Derivative|differentiation]].