---
tags:
  - university-notes
university-name: Virtual University of Pakistan
date: 2025-04-18
---

# 14. Partitioned Matrices

<span style="color: gray;">Dated: 18-04-2025</span>  

A `block matrix` or a `partitioned matrix` is a partition of a `matrix`[^1] into rectangular smaller `matrices`[^1] called `blocks`.

## Example

$$
P = \begin{bmatrix} 1 & 1 & 2 & 2 \\ 1 & 1 & 2 & 2 \\ 3 & 3 & 4 & 4 \\ 3 & 3 & 4 & 4 \end{bmatrix}
$$

$P$ can be partitioned as

$$
P_{11} = \begin{bmatrix} 1 & 1 \\ 1 & 1 \end{bmatrix}, \quad P_{12} = \begin{bmatrix} 2 & 2 \\ 2 & 2 \end{bmatrix}, \quad P_{21} = \begin{bmatrix} 3 & 3 \\ 3 & 3 \end{bmatrix}, \quad P_{22} = \begin{bmatrix} 4 & 4 \\ 4 & 4 \end{bmatrix}
$$

$$
P = \begin{bmatrix} P_{11} & P_{12} \\ P_{21} & P_{22} \end{bmatrix}
$$

## Column Matrices

$$
A = \left[
	\begin{array}{c|c|c}
		a_{11} & a_{12} & a_{13} \\
		a_{21} & a_{22} & a_{23} \\
		a_{31} & a_{32} & a_{33} \\
		a_{41} & a_{42} & a_{43} \\
		a_{51} & a_{52} & a_{53} \\
	\end{array}
\right]
= \left[ \, C_1 \; \middle| \; C_2 \; \middle| \; C_3 \, \right]
$$

$C_1, C_2$ and $C_3$ are called `column matrices` of $A$.

## Row Matrices

$$
A = \left[
\begin{array}{ccc}
a_{11} & a_{12} & a_{13} \\
\hline
a_{21} & a_{22} & a_{23} \\
\hline
a_{31} & a_{32} & a_{33} \\
\hline
a_{41} & a_{42} & a_{43} \\
\hline
a_{51} & a_{52} & a_{53} \\
\end{array}
\right]
=
\left[
\begin{array}{c}
R_1 \\
\hline
R_2 \\
\hline
R_3 \\
\hline
R_4 \\
\hline
R_5 \\
\end{array}
\right]
$$

$R_1, R_2, R_3, R_4$ and $R_5$ are `row matrices` of $A$.

## Addition of Blocked Matrices

If $A$ and $B$ are `matrices`[^1] of same size and are partitioned in the same way then each `block` of $A + B$ is sum of corresponding `blocks` of $A$ and $B$.

### Theorem

If $A$ is $m \times n$ and $B$ is $n \times p$ then

$$AB = 
\begin{bmatrix}
	\text{Col}_1(A) & \text{Col}_2(A) & \ldots & \text{Col}_n(A)
\end{bmatrix}
\begin{bmatrix}
	\text{Row}_1(B)\\
	\text{Row}_2(B)\\
	\vdots \\
	\text{Row}_n(B)\\
\end{bmatrix}
$$

$$
	= \text{Col}_1(A) \text{Row}_1(B) + 
	\text{Col}_2(A) \text{Row}_2(B) + 
	\cdots
	\text{Col}_n(A) \text{Row}_n(B)
$$

## Multiplication of Partitioned Matrices

$$
A = \begin{bmatrix} A_{11} & A_{12} \\ A_{21} & A_{22} \\ A_{31} & A_{32} \end{bmatrix} \text{ and } B = \begin{bmatrix} B_{11} & B_{12} \\ B_{21} & B_{22} \end{bmatrix}
$$

$$
AB = \begin{bmatrix} A_{11} & A_{12} \\ A_{21} & A_{22} \\ A_{31} & A_{32} \end{bmatrix} \begin{bmatrix} B_{11} & B_{12} \\ B_{21} & B_{22} \end{bmatrix} = \begin{bmatrix} A_{11}B_{11} + A_{12}B_{21} & A_{11}B_{12} + A_{12}B_{22} \\ A_{21}B_{11} + A_{22}B_{21} & A_{21}B_{12} + A_{22}B_{22} \\ A_{31}B_{11} + A_{32}B_{21} & A_{31}B_{12} + A_{32}B_{22} \end{bmatrix}
$$

It is known as `block multiplication`.

## Example

$$
A = \begin{bmatrix} 1 & 0 & 0 & 0 & 0 & 1 \\ 0 & 1 & 0 & 0 & 0 & 1 \\ 0 & 0 & 1 & 0 & 0 & 1 \\ 0 & 0 & 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 0 & 1 & 0 \\ 1 & 1 & 1 & 0 & 0 & 1 \end{bmatrix}
$$

Evaluate $A^2$

### Solution

$$
A = \left[ 
	\begin{array}{ccc|cc|c}
		1 & 0 & 0 & 0 & 0 & 1 \\
		0 & 1 & 0 & 0 & 0 & 1 \\
		0 & 0 & 1 & 0 & 0 & 1 \\
		\hline
		0 & 0 & 0 & 1 & 0 & 0 \\
		0 & 0 & 0 & 0 & 1 & 0 \\
		\hline
		1 & 1 & 1 & 0 & 0 & 1
	\end{array}
\right]
= 
\begin{bmatrix}
	I_3 & O_{32} & A_1 \\
	O_{23} & I_2 & O_{21} \\
	A_1^t & O_{12} & 1 
\end{bmatrix}
$$

Where 

$$
A_1 =
\begin{bmatrix}
	1\\
	1\\
	1
\end{bmatrix}
$$

$$
A^2 = \begin{bmatrix} I_3 & O_{32} & A_1 \\ O_{23} & I_2 & O_{21} \\ A_1^t & O_{12} & 1 \end{bmatrix} \begin{bmatrix} I_3 & O_{32} & A_1 \\ O_{23} & I_2 & O_{21} \\ A_1^t & O_{12} & 1 \end{bmatrix} = \begin{bmatrix} I_3 + A_1A_1^t & O_{32} & A_1 + A_1 \\ O_{23} & I_2 & O_{21} \\ A_1^t + A_1^t & O_{12} & A_1^t A_1 + 1 \end{bmatrix}
$$

$$
I_3 + A_1A_1^t = \begin{bmatrix} 2 & 1 & 1 \\ 1 & 2 & 1 \\ 1 & 1 & 2 \end{bmatrix}
$$

$$
A_1 + A_1 = \begin{bmatrix} 2 \\ 2 \\ 2 \end{bmatrix}
$$

$$
A_1^t + A_1^t = \begin{bmatrix} 2 & 2 & 2 \end{bmatrix}
$$

$$
A_1^t A_1 + 1 = [4]
$$

$$
A^2 = 
\left[
\begin{array}{ccc|cc|c}
	2 & 1 & 1 & 0 & 0 & 2 \\
	1 & 2 & 1 & 0 & 0 & 2 \\
	1 & 1 & 2 & 0 & 0 & 2 \\
	\hline
	0 & 0 & 0 & 1 & 0 & 0 \\
	0 & 0 & 0 & 0 & 1 & 0 \\
	\hline
	2 & 2 & 2 & 0 & 0 & 4 
\end{array}
\right]
$$

$$
A^2 = 
\begin{bmatrix}
	2 & 1 & 1 & 0 & 0 & 2 \\
	1 & 2 & 1 & 0 & 0 & 2 \\
	1 & 1 & 2 & 0 & 0 & 2 \\
	0 & 0 & 0 & 1 & 0 & 0 \\
	0 & 0 & 0 & 0 & 1 & 0 \\
	2 & 2 & 2 & 0 & 0 & 4 
\end{bmatrix}
$$

## Toeplitz Matrix

A `matrix`[^1] in which each descending `diagonal` from left to right is constant is called a `Toeplitz matrix` or `diagonal-constant matrix`.

### Example

$$
A = \begin{bmatrix} a & 1 & 2 & 3 \\ 4 & a & 1 & 2 \\ 5 & 4 & a & 1 \\ 6 & 5 & 4 & a \end{bmatrix}
$$

## Block Toeplitz Matrix

A `blocked matrix` in which `blocks` (`blocked matrices`) are repeated down the `diagonals` of the `matrix`[^1] is called a `blocked Toeplitz matrix`.

$$
B = \begin{bmatrix}
B(1,1) & B(1,2) & B(1,3) & B(1,4) & B(1,5) \\
B(2,1) & B(1,1) & B(1,2) & B(1,3) & B(1,4) \\
B(3,1) & B(2,1) & B(1,1) & B(1,2) & B(1,3) \\
B(4,1) & B(3,1) & B(2,1) & B(1,1) & B(1,2) \\
B(5,1) & B(4,1) & B(3,1) & B(2,1) & B(1,1)
\end{bmatrix}
$$

## Inverses of Partitioned Matrices

### Block Diagonal Matrices

$$
A = \begin{bmatrix}
D_1 & 0 & \cdots & 0 \\
0 & D_2 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & D_k
\end{bmatrix}
$$

Where $D_1, D_2$ and $D_k$ are `square matrices`.[^1]  
It's inverse can be found out as

$$
A^{-1} = \begin{bmatrix}
	D_1^{-1} & 0 & \cdots & 0 \\
	0 & D_2^{-1} & \cdots & 0 \\
	\vdots & \vdots & \ddots & \vdots \\
	0 & 0 & \cdots & D_k^{-1}
\end{bmatrix}
$$

### Block Upper Triangular Matrices

$$
A = \begin{bmatrix}
A_{11} & A_{12} & \cdots & A_{1k} \\
O & A_{22} & \cdots & A_{2k} \\
\vdots & \vdots & \ddots & \vdots \\
O & O & \cdots & A_{kk}
\end{bmatrix}
$$

Where $A_{11}, A_{22}$ and $A_{kk}$ are `square`.

#### Example

Let $A$ be a `block upper triangular matrix`.

$$
A =
\begin{bmatrix}
	A_{11} & A_{12}\\
	0 & A_{22}
\end{bmatrix}
$$

Where the `order`[^1] of $A_{11}$ is $p \times p$ and that of $A_{22}$ is $q \times q$ respectively.  
Find $A^{-1}$

##### Solution

$$
B =
\begin{bmatrix}
	B_{11} & B_{12}\\
	B_{21} & B_{22}
\end{bmatrix}
$$

$$B = A^{-1}$$

$$
AB = \begin{bmatrix} A_{11} & A_{12} \\ O & A_{22} \end{bmatrix} \begin{bmatrix} B_{11} & B_{12} \\ B_{21} & B_{22} \end{bmatrix} = \begin{bmatrix} I_p & O \\ O & I_q \end{bmatrix}
$$

$$
\begin{bmatrix} A_{11}B_{11} + A_{12}B_{21} & A_{11}B_{12} + A_{12}B_{22} \\ A_{22}B_{21} & A_{22}B_{22} \end{bmatrix} = \begin{bmatrix} I_p & O \\ O & I_q \end{bmatrix}
$$

$$
A_{11}B_{11} + A_{12}B_{21} = I_p
$$

$$
A_{11}B_{12} + A_{12}B_{22} = O
$$

$$
A_{22}B_{21} = O
$$

$$
A_{22}B_{22} = I_q
$$

###### $B_{22} = ?$

$$
A_{22}B_{22} = I_q
$$

$$
A_{22}^{-1}A_{22}B_{22} = A^{-1}_{22}I_q
$$

$$
I_{q}B_{22} = A^{-1}_{22}
$$

$$
B_{22} = A^{-1}_{22}
$$

###### $B_{21} = ?$

$$
A_{22}B_{21} = O
$$

$$
A_{22}^{-1}A_{22}B_{21} = A^{-1}_{22}O
$$

$$
I_{q}B_{21} = O
$$

$$
B_{21} = O
$$

###### $B_{11} = ?$

$$
A_{11}B_{11} + O = I_p \\
\implies A_{11}B_{11} = I_p \\
\implies B_{11} = A_{11}^{-1}
$$

###### $B_{12} = ?$

$$
A_{11}B_{12} + A_{12}B_{22} = O
$$

$$
A_{11}B_{12} = -A_{12}B_{22}
$$

$$
A^{-1}_{11}A_{11}B_{12} = A_{11}^{-1}-A_{12}B_{22}
$$

$$
I_1B_{12} = A_{11}^{-1}-A_{12}B_{22}
$$

$$
B_{12} = A_{11}^{-1}-A_{12}A_{22}^{-1} \quad \because B_{22}=A^{-1}_{22}
$$

$$
A^{-1} = \begin{bmatrix} A_{11} & A_{12} \\ O & A_{22} \end{bmatrix}^{-1} = \begin{bmatrix} A_{11}^{-1} & -A_{11}^{-1}A_{12}A_{22}^{-1} \\ O & A_{22}^{-1} \end{bmatrix}
$$

## References

Read more about [[M_Notations|notations and symbols]].

[^1]: Read more about [[mth501_02|matrices]].