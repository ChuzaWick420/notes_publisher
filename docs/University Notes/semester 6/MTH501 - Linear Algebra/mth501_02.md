---
tags:
  - university-notes
university-name: Virtual University of Pakistan
date: 2025-03-10
---

# 02. Introduction to Matrices

<span style="color: gray;">Dated: 10-03-2025</span>

## Matrix

A `matrix` is a collection or an `array` of `numbers`[^1] or `functions`[^2] (both are called `members`, `entry` or `elements` of the `matrix`) arranged in rows and columns.

### Denotation

The [matrix](#matrix) is denoted by capital letters such as $A, B$ etc meanwhile its `members` are represented by small letters such as $a, b$ etc.

### Order

The order is the size or dimension of a [matrix](#matrix), written as $r \times c$ where $r$ represents the number of rows and $c$ represents the number of columns.

$$
A = 
\left[
\begin{matrix}
	a_{11} & a_{12} & \cdots & a_{1n} \\
	a_{21} & a_{22} & \cdots & a_{2n} \\
	\vdots & \vdots & \ddots & \vdots \\
	a_{m1} & a_{m2} & \cdots & a_{mn}
\end{matrix}
\right]
$$

In general terms, the `element` in $i^{\text{th}}$ row and $j^\text{th}$ column of a $m \times n$ [matrix](#matrix) can be written as $a_{\text{ij}}$.

#### Example

The following [matrix](#matrix) has an `order` of $2 \times 3$ with $2$ rows and $3$ columns.

$$
A = \left[
\begin{matrix}
	2 & -1 & 3\\
	0 & 4 & 6
\end{matrix}
\right]
$$

### Square Matrix

A [matrix](#matrix) is called a `square matrix` if the number of rows is equal to the number of columns.

$$
A = \left[
\begin{matrix}
	1 & 2\\
	3 & 4
\end{matrix}
\right]
$$

### Equal Matrices

Two [matrices](#matrix) are called `equal matrices` if

- They have same dimensions.
- The corresponding `entries` are equal. 

$$
A = \left[
\begin{matrix}
	1 & 2\\
	3 & 4
\end{matrix}
\right]
\quad
\text{ and }
\quad
B = \left[
\begin{matrix}
	1 & 2\\
	3 & 4
\end{matrix}
\right]
$$

Both are `equal matrices`.

### Column Matrix

A [matrix](#matrix) is called a `column matrix` if it has only one column and $n$ rows.

$$X = \left[
\begin{matrix}
	a_{11}\\
	a_{21}\\
	\vdots\\
	a_{n1}\\
\end{matrix}
\right]
= [b_{\text{i1}}]_{n \times 1}
$$

A `column matrix` is also called a `column vector` or simply a `vector`.[^3]

### Multiple of a Matrix

If $A$ is a [matrix](#matrix) and $k$ is a non-zero constant then

$$
kA = 
k\left[
\begin{matrix}
	a_{11} & a_{12} & \cdots & a_{1n} \\
	a_{21} & a_{22} & \cdots & a_{2n} \\
	\vdots & \vdots & \ddots & \vdots \\
	a_{m1} & a_{m2} & \cdots & a_{mn}
\end{matrix}
\right]
$$

$$
=
\left[
\begin{matrix}
	ka_{11} & ka_{12} & \cdots & ka_{1n} \\
	ka_{21} & ka_{22} & \cdots & ka_{2n} \\
	\vdots & \vdots & \ddots & \vdots \\
	ka_{m1} & ka_{m2} & \cdots & ka_{mn}
\end{matrix}
\right]
$$

$$= [ka_{\text{ij}}]_{m \times n}$$

> [!TIP]- Commutative property of scalar multiplication  
> 
> $$kA = Ak$$

### Addition of Matrices

If $A = [a_{\text{ij}}]$ and $B = [b_{\text{ij}}]$ are [matrices](#matrix) of [order](#order) $m \times n$ then $A + B = [a_{\text{ij}} + b_{\text{ij}}]_{m \times n}$.

### Difference of Matrices

Similar to [addition](#addition), $A - B$ can be written as $A + (-B)$ where $-B = -1 \times B$.

### Product of Matrices

$$A_{m \times n} \cdot B_{n \times p} = C_{m \times p}$$

$$
A = 
\left[
\begin{matrix}
	a_{11} & a_{12} & \cdots & a_{1n} \\
	a_{21} & a_{22} & \cdots & a_{2n} \\
	\vdots & \vdots & \ddots & \vdots \\
	a_{m1} & a_{m2} & \cdots & a_{mn}
\end{matrix}
\right]
$$

$$
B = 
\left[
\begin{matrix}
	b_{11} & b_{12} & \cdots & b_{1n} \\
	b_{21} & b_{22} & \cdots & b_{2n} \\
	\vdots & \vdots & \ddots & \vdots \\
	b_{n1} & b_{n2} & \cdots & b_{np}
\end{matrix}
\right]
$$

$$A \times B = AB = 
\left[
\begin{matrix}
	a_{11} & a_{12} & \cdots & a_{1n} \\
	a_{21} & a_{22} & \cdots & a_{2n} \\
	\vdots & \vdots & \ddots & \vdots \\
	a_{m1} & a_{m2} & \cdots & a_{mn}
\end{matrix}
\right]
\left[
\begin{matrix}
	b_{11} & b_{12} & \cdots & b_{1n} \\
	b_{21} & b_{22} & \cdots & b_{2n} \\
	\vdots & \vdots & \ddots & \vdots \\
	b_{n1} & b_{n2} & \cdots & b_{np}
\end{matrix}
\right]
$$

$$
=
\left[
\begin{matrix}
	a_{11}b_{11} + a_{12}b_{21} + \cdots + a_{1n}b_{n1} & \cdots & a_{11}b_{1p} + a_{12}b_{2p} + \cdots + a_{1n}b_{np}\\
	a_{21}b_{11} + a_{22}b_{21} + \cdots + a_{2n}b_{n1} & \cdots & a_{21}b_{1p} + a_{22}b_{2p} + \cdots + a_{2n}b_{np}\\
	\vdots & \vdots & \vdots \\
	a_{m1}b_{11} + a_{m2}b_{21} + \cdots + a_{mn}b_{n1} & \cdots & a_{m1}b_{1p} + a_{m2}b_{2p} + \cdots + a_{mn}b_{np}\\
\end{matrix}
\right]
$$

$$
= \left(
\sum_{k = 1}^n a_{ik}b_{kj}
\right)_{n \times p}
$$

> [!TIP] $AB \neq BA$

For two [matrices](#matrix) to be eligible for multiplication, the number of columns of the first one has to be equal to number of rows of second one.

$$A_{m \times n} \cdot B_{n \times p} = C_{m \times p}$$

### Multiplicative Identity

$$
I = 
\left[
\begin{matrix}
	1 & 0 & \cdots & 0 \\
	0 & 1 & \cdots & 0 \\
	\vdots & \vdots & \ddots & \vdots \\
	0 & 0 & \cdots & 1
\end{matrix}
\right]
$$

$$A \times I = I \times A = A$$

### Zero or Null Matrix

A [matrix](#matrix) with all `entries` being $0$ is called a `null matrix`.

$$
O = \left[
\begin{matrix}
0 & 0\\
0 & 0
\end{matrix}
\right]
$$

$$
O = \left[  
\begin{matrix}  
	0\\  
	0  
\end{matrix}  
\right]

$$

### Associative Law

If $A, B$ and $C$ are three [matrices](#matrix) then  

$$A(BC) = (AB)C$$

### Distributive Law

If $A, B$ and $C$ are three [matrices](#matrix) then

$$A(B + C) = AB + AC$$

$$(A + B)C = AC + BC$$

### Remarks

There are some rules from $\mathbb R$ which do not carry over to [matrix addition](#addition-of-matrices).  
For example, $\forall a, b, c, d \in \mathbb R$,

1. $ab = cd \land a \neq 0 \implies b = c$ (Law of Cancellation)
2. $ab = 0 \implies a = 0 \lor b = 0$.

### Determinant of a Matrix

The `determinant` is a special number associated with every [square matrix](#square-matrix) and is denoted by $\det(A)$ or $|A|$.

$$
A_{2 \times 2} = 
\left[
\begin{matrix}
1 & 2\\
3 & 4
\end{matrix}
\right]
$$

$$
|A_{2 \times 2}| = 
\left|
\begin{matrix}
1 & 2\\
3 & 4
\end{matrix}
\right|
=
(1 \times 4) - (3 \times 2)
= 
4 - 6 = -2
$$

$$
A_{3 \times 3} = 
\left[
\begin{matrix}
3 & 6 & 2 \\
2 & 5 & 1 \\
-1 & 2 & 4
\end{matrix}
\right]
$$

$$
|A_{3 \times 3}| = 
\left|
\begin{matrix}
3 & 6 & 2 \\
2 & 5 & 1 \\
-1 & 2 & 4
\end{matrix}
\right|
$$

$$
\begin{vmatrix}
3 & 6 & 2 \\
2 & 5 & 1 \\
-1 & 2 & 4
\end{vmatrix}
= 3\begin{vmatrix}
5 & 1 \\
2 & 4
\end{vmatrix}
- 6\begin{vmatrix}
2 & 1 \\
-1 & 4
\end{vmatrix}
+ 2\begin{vmatrix}
2 & 5 \\
-1 & 2
\end{vmatrix}
$$

$$
3(20 - 2) - 6(8 +1) + 2(4 + 5) = 18
$$

### Transpose of a Matrix

If $A_{m \times n}$ is a [matrix](#matrix) with $m$ rows and $n$ columns then its `transpose` $A_{m \times n}^T = A_{n \times m}$ can be obtained by interchanging its rows with columns.

$$
A = 
\left[
\begin{matrix}
	a_{11} & a_{12} & \cdots & a_{1n} \\
	a_{21} & a_{22} & \cdots & a_{2n} \\
	\vdots & \vdots & \ddots & \vdots \\
	a_{m1} & a_{m2} & \cdots & a_{mn}
\end{matrix}
\right]
$$

$$
A^T = 
\left[
\begin{matrix}
	a_{11} & a_{21} & \cdots & a_{m1} \\
	a_{12} & a_{22} & \cdots & a_{m2} \\
	\vdots & \vdots & \ddots & \vdots \\
	a_{1n} & a_{2n} & \cdots & a_{mn}
\end{matrix}
\right]
$$

#### Properties

- $(kA)^T= k A^T$
- $(A + B)^T = A^T + B^T$
- $(ABC)^T = C^TB^TA^T$

### Multiplicative Inverse

If $A_{n \times n}$ and $B_{n \times n}$ are [matrices](#matrix) then $B_{n \times n}$ is called the `multiplicative inverse` of $A_{n \times n}$ if  

$$AB = BA = I$$

And it is denoted as $B = A^{-1}$

### Singular and Non Singular Matrix

A [matrix](#matrix) $A$ is called `singular` if $\det(A) = 0$ otherwise if $\det(A) \neq 0$ is called `non singular matrix`.

### Minor of an Element of a Matrix

Let $A_{n \times n}$ be a [matrix](#matrix) then `minor` $M_{ij}$ of the `element` $a_{ij} \in A$ is the determinant of the [matrix](#matrix) $B_{(n - 1) \times (n - 1)}$ obtained by deleting the $i^{\text{th}}$ row and $j^{\text{th}}$ column from $A$.

### Co-factor of an Element of a Matrix

If $C_{ij}$ is the `cofactor` of $a_{ij}$ `element` then  

$$C_{ij} = (-1)^{i + j} M_{ij}$$

### Theorem

$$\det(A_{n \times n})\iff A_{n \times n}^{-1} \quad \text{exists}$$

### Theorem

$$A^{-1} = \frac{C_{ij}^T}{\det(A)}$$

### Derivative of a Matrix of `Functions`[^2]

If $A(t)$ is a [matrix](#matrix) with `elements` which are `functions` which are `differentiable`[^4] on a common `interval`[^5]

$$A(t) = [a_{ij}(t)]_{m \times n}$$

then  

$$\frac{d}{dt} A(t) = \left[\frac{d a_{ij}}{dt}\right]_{m \times n}$$

It can be denoted as $A^\prime(t)$.

### Integral of a Matrix of `Functions`[^2]

If $A(s)$ is a [matrix](#matrix) with `elements` which are `functions` which are `continuous`[^6] on a common `interval`[^5] containing $t$  

$$
\int_{t_0}^t A(s) ds = \left[
	\int_{t_0}^t a_{ij}(s)ds
\right]_{m \times n}
$$

## References

Read more about [[M_Notations|notations and symbols]].

[^1]: Read more about [[M_Numbers|numbers]].
[^2]: Read more about [[M_Function|functions]].
[^3]: Read more about [[10. Introduction to vectors|vectors]].
[^4]: Read more about [[15. The Derivative|differentiation]].
[^5]: Read more about [[1. Coordinates, Graphs, Lines|intervals]].
[^6]: Read more about [[12. Continuity|continuous]].